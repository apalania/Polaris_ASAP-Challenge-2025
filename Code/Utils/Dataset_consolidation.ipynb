{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#FOR MERGING THE DATASETS TO FILTER UNIQUE SMILES AND SMILE CONTAINING TWO DIFFERENT VALUES KEEP THEM AS AS UNIQUE SMILES AS THEY MAY BE A ENANTIOMERS\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "df1 = pd.read_csv(\"/content/dataset1.csv\")\n",
        "df2 = pd.read_csv(\"/content/dataset2.csv\")\n",
        "\n",
        "# Print dataset details before merging\n",
        "print(\"Before Merging:\")\n",
        "print(f\"Rows in df1: {len(df1)}, Columns in df1: {df1.shape[1]}\")\n",
        "print(f\"Rows in df2: {len(df2)}, Columns in df2: {df2.shape[1]}\")\n",
        "print(f\"Unique SMILES in df1: {df1['smiles'].nunique()}\")\n",
        "print(f\"Unique SMILES in df2: {df2['smiles'].nunique()}\")\n",
        "\n",
        "# Check missing values per column before merging\n",
        "print(\"\\nMissing values per column in df1:\")\n",
        "print(df1.isnull().sum())\n",
        "\n",
        "print(\"\\nMissing values per column in df2:\")\n",
        "print(df2.isnull().sum())\n",
        "\n",
        "# Merge datasets while preserving duplicate SMILES entries\n",
        "df_merged = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "# Handle duplicate columns (excluding 'smiles')\n",
        "common_cols = set(df1.columns) & set(df2.columns) - {\"smiles\"}\n",
        "\n",
        "for col in common_cols:\n",
        "    col_x, col_y = f\"{col}_x\", f\"{col}_y\"\n",
        "    if col_x in df_merged.columns and col_y in df_merged.columns:\n",
        "        df_merged[col] = df_merged[col_x].combine_first(df_merged[col_y])\n",
        "        df_merged.drop(columns=[col_x, col_y], inplace=True)\n",
        "\n",
        "# Print dataset details after merging\n",
        "print(\"\\nAfter Merging:\")\n",
        "print(f\"Rows in Merged Dataset: {len(df_merged)}, Columns in Merged Dataset: {df_merged.shape[1]}\")\n",
        "print(f\"Unique SMILES in Merged Dataset: {df_merged['smiles'].nunique()}\")\n",
        "\n",
        "# Check missing values per column after merging\n",
        "print(\"\\nMissing values per column after merging:\")\n",
        "print(df_merged.isnull().sum())\n",
        "\n",
        "# Save the final dataset\n",
        "df_merged.to_csv(\"OUTPUT.csv\", index=False)\n",
        "\n",
        "print(\"\\nFinal dataset saved successfully!\")\n"
      ],
      "metadata": {
        "id": "mCIW2KK1PVit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FOR REMOVING EMPTY FILES\n",
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('DATASET.csv')\n",
        "\n",
        "# Remove rows where all columns (except 'smiles') have NaN values\n",
        "df_cleaned = df.dropna(subset=df.columns[1:], how='all')\n",
        "\n",
        "# Save the cleaned dataset to a new CSV file\n",
        "df_cleaned.to_csv('OUTPUT.csv', index=False)\n",
        "\n",
        "print(\"Rows with no values have been removed.\")"
      ],
      "metadata": {
        "id": "eBn33KMje7fP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8x9_w58j6wj"
      },
      "outputs": [],
      "source": [
        "#FOR THE DATASETS TO REMOVE ALL DUPLICATE SMILES AND VALUES\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "df1 = pd.read_csv(\"/content/dataset1.csv\")\n",
        "df2 = pd.read_csv(\"/content/DATASET2.csv\")\n",
        "\n",
        "# Print dataset details before merging\n",
        "print(\"Before Merging:\")\n",
        "print(f\"Rows in df1: {len(df1)}, Columns in df1: {df1.shape[1]}\")\n",
        "print(f\"Rows in df2: {len(df2)}, Columns in df2: {df2.shape[1]}\")\n",
        "print(f\"Unique SMILES in df1: {df1['smiles'].nunique()}\")\n",
        "print(f\"Unique SMILES in df2: {df2['smiles'].nunique()}\")\n",
        "\n",
        "# Check missing values per column before merging\n",
        "print(\"\\nMissing values per column in df1:\")\n",
        "print(df1.isnull().sum())\n",
        "\n",
        "print(\"\\nMissing values per column in df2:\")\n",
        "print(df2.isnull().sum())\n",
        "\n",
        "# Merge datasets\n",
        "df_merged = pd.merge(df1, df2, on=\"smiles\", how=\"outer\")\n",
        "\n",
        "# Handle duplicate columns\n",
        "for col in df1.columns:\n",
        "    if col in df2.columns and col != \"smiles\":  # Exclude 'smiles'\n",
        "        col_x, col_y = f\"{col}_x\", f\"{col}_y\"\n",
        "        if col_x in df_merged.columns and col_y in df_merged.columns:\n",
        "            df_merged[col] = df_merged[col_x].combine_first(df_merged[col_y])\n",
        "            df_merged.drop(columns=[col_x, col_y], inplace=True)\n",
        "\n",
        "# Print dataset details after merging\n",
        "print(\"\\nAfter Merging:\")\n",
        "print(f\"Rows in Merged Dataset: {len(df_merged)}, Columns in Merged Dataset: {df_merged.shape[1]}\")\n",
        "print(f\"Unique SMILES in Merged Dataset: {df_merged['smiles'].nunique()}\")\n",
        "\n",
        "# Check if any columns were lost or added\n",
        "print(\"\\nColumns added after merging:\", set(df_merged.columns) - set(df1.columns) - set(df2.columns))\n",
        "print(\"Columns missing after merging:\", set(df1.columns) | set(df2.columns) - set(df_merged.columns))\n",
        "\n",
        "# Check missing values per column after merging\n",
        "print(\"\\nMissing values per column after merging:\")\n",
        "print(df_merged.isnull().sum())\n",
        "\n",
        "# Save the final dataset\n",
        "df_merged.to_csv(\"output.csv\", index=False)\n",
        "\n",
        "print(\"\\nFinal dataset saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to get total colums with entered values and missing values\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "file_path = \"/content/output.csv\"  # Replace with your actual file path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Calculate counts\n",
        "total_rows = len(df)  # Total number of rows\n",
        "entered_values = df.count()  # Non-null values per column\n",
        "missing_values = total_rows - entered_values  # Null values per column\n",
        "\n",
        "# Combine into a DataFrame for better readability\n",
        "summary = pd.DataFrame({\n",
        "    \"Column Name\": df.columns,\n",
        "    \"Entered Values\": entered_values,\n",
        "    \"Missing Values\": missing_values\n",
        "})\n",
        "\n",
        "# Print the summary\n",
        "print(summary)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEiSKH4UO-VD",
        "outputId": "53887138-9ef1-4d01-cbe9-4da1591a5b89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Column Name  Entered Values  Missing Values\n",
            "smiles      smiles            1513               0\n",
            "pIC50        pIC50            1513               0\n"
          ]
        }
      ]
    }
  ]
}